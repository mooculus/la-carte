\documentclass{ximera}

\input{../../preamble.tex}

\author{Parisa Fatheddin \and Bart Snapp}

%% Jim Hefferonâ€™s Linear Algebra. (CC-BY-NC-SA)
%% Anna Davis and Paul Zachlin: https://github.com/annadavismath/LinearAlgebraV2
%% https://ximera.osu.edu/linearalgebrav3/LinearAlgebraInteractiveIntro/SYS-0030/main

%% https://www.cis.upenn.edu/~cis6100/Notices-06-11-Gausselim.pdf
%% https://www.sciencedirect.com/science/article/pii/S0315086010000376


\title{Matrices and systems of linear equations}




\begin{document}
\begin{abstract}
  We use matrices to solve systems of linear equations.
\end{abstract}
\maketitle

Gaussian elimination is technique for solving systems of linear
equations. It is (obviously) named after
\link[Gauss]{https://en.wikipedia.org/wiki/Carl_Friedrich_Gauss}
($1799$--$1855$). However, it was known to
\link[Legendre]{https://en.wikipedia.org/wiki/Adrien-Marie_Legendre}
($1752$--$1833$) and even
\link[Euler]{https://en.wikipedia.org/wiki/Leonhard_Euler}
($1707$--$1783$) before him. Moreover, it seems that these \textit{legends of
mathematics} did not think highly of the method: Gauss refereed to it
as ``common;'' Legendre called it ``ordinary;'' Euler ``did not
recommend'' this method to students.




Despite this inauspicious start, \textbf{Gaussian elimination is a
  tremendously important technique today.} It reduces a problem to
it's barest components, and gives a method, an algorithm, that can be
programmed into a computer that will solve systems of linear
equations. Our mathematical heroes' disdain for this method is a
consequence of the fact that \textit{not even they could have dreamt of the awesome
computational power of modern computers.}



\section{Row operations on matrices}


Any time we have a \dfn{system of equations} we may represent it with a
\dfn{matrix}
\[
\begin{array}{ccccccc}
       & & 3y &-& 3z &=& -3 \\
     x& +&3y&-&3z&=&2\\
     -3x& -&9y&-&11z&=&0
\end{array}
\qquad\Longrightarrow\qquad
\left(\begin{array}{ccc|c}
  0 &   3 & -3 & -3 \\
  1 &   3 & -3 & 2  \\
  -3& -9  & 11 & 0
\end{array}\right).
\]
This is an example of a matrix used to store data. Some folks call
this an \dfn{augmented matrix}, and they write stuff like this:
\[
A = \underbrace{\begin{pmatrix}
  0 & 3 & -3  \\
  1 &  3  & -3 \\
 -3 & -9 & 11
\end{pmatrix}}_{\text{the coefficients}},
\quad
B =
\underbrace{\begin{pmatrix}
 -3\\ 2 \\ 0 
\end{pmatrix}}_{\text{right-hand side}},
\quad
\left(A|B\right) = \underbrace{\left(\begin{array}{ccc|c}
  0 &   3 & -3 & -3 \\
  1 &   3 & -3 & 2  \\
  -3& -9  & 11 & 0
\end{array}\right)}_{\text{augmented matrix}}.
\]

\begin{question}
  Consider the following system of equations:

  Write the augmented matrix for this system of equations.
  \begin{prompt}
    \[
    \left(\begin{array}{ccc|c}
      \answer{} & \answer{} & \answer{} & \answer{}
    \end{array}\right)
    \]
  \end{prompt}
\end{question}

We are going to use matrices to solve this system of equations. The
method we describe below is often called \dfn{Gaussian elimination}
or simply \dfn{elimination}. To do this, we're going to introduce
\dfn{row operations}. The row operations will allow us to change the
form of the matrix \emph{without changing the solutions}. The idea is
this we start with a big matrix,
\[
\begin{pmatrix}
  \bullet & \bullet & \bullet & \bullet \\
  \bullet & \bullet & \bullet & \bullet \\
  \bullet & \bullet & \bullet & \bullet 
\end{pmatrix}
\quad
\Rightarrow
\quad
\begin{pmatrix}
  \bullet & \bullet & \bullet & \bullet \\
     0   & \bullet & \bullet & \bullet \\
     0  &    0 & \bullet & \bullet 
\end{pmatrix}
\quad
\Rightarrow
\quad
\begin{pmatrix}
  1 & 0 & 0  & \bullet \\
     0   & 1  &  0 & \bullet \\
     0  &    0 & 1 & \bullet 
\end{pmatrix}
\]
and transform it into a form where we can simply ``read-off'' the
information about the system of equations, including the solutions.  We
discuss the row operations that allow such a transformation below.



\subsection{Swapping two rows} Since swapping the order of the equations in a
  system of equations does not change the solutions, we may swap rows
  in an augmented matrix. We denote swapping the $i$th row with the
  $j$th row by $R_i\leftrightarrow R_j$. As an example, we can swap
  the first and second rows of the matrix below:
 \[
\left(\begin{array}{ccc|c}
  0 &   3 & -3 & -3 \\
  1 &   3 & -3 & 2  \\
  -3& -9  & 11 & 0
\end{array}\right)
\qquad
\begin{array}{c}
  R_1\leftrightarrow R_2\\\Longrightarrow
\end{array}
\qquad
\left(\begin{array}{ccc|c}
  1 &   3 & -3 & 2  \\
  0 &   3 & -3 & -3 \\
  -3& -9  & 11 & 0
\end{array}\right)
\]

\begin{question}
\end{question}

  
\subsection{Multiply by a nonzero constant and add different rows} 
We may multiply equations by nonzero constants and add equations together
\emph{without affecting the solution.} Hence we may multiply the first
row by $3$ and add it to the third row, storing the answer in the
third row (you could have chosen either of the summands).
\[
\left(\begin{array}{ccc|c}
  1 &   3 & -3 & 2  \\
  0 &   3 & -3 & -3 \\
  -3& -9  & 11 & 0
\end{array}\right)
\qquad
\begin{array}{c}
  3R_1+R_3\rightarrow R_3\\\Longrightarrow
\end{array}
\qquad
\left(\begin{array}{ccc|c}
  1 &   3 & -3 & 2  \\
  0 &   3 & -3 & -3 \\
  0& 0  & 2 & 6
\end{array}\right).
\]

\begin{question}
\end{question}



At this point, we should draw your attention to the \emph{form} of the matrix. This matrix

\[
\begin{pmatrix}
  1 &   3 & -3 & 2  \\
  0 &   3 & -3 & -3 \\
  0& 0  & 2 & 6
\end{pmatrix}
\qquad
\text{is of this form:}
\qquad
\begin{pmatrix}
  \bullet & \bullet & \bullet & \bullet \\
     0   & \bullet & \bullet & \bullet \\
     0  &    0 & \bullet & \bullet 
\end{pmatrix}
\]



We'll discuss the implications of this form below.


\section{Row echelon form}

We can write many different matrices that all represent systems
of equations that have a common solution. For example:
\[
\begin{pmatrix}
 0 &   3 & -3 & -3 \\
  1 &   3 & -3 & 2  \\
  -3& -9  & 11 & 0
\end{pmatrix},
\quad
\begin{pmatrix}
  1 &   3 & -3 & 2  \\
  0 &   3 & -3 & -3 \\
  -3& -9  & 11 & 0
\end{pmatrix},
\quad
\begin{pmatrix}
  1 &   3 & -3 & 2  \\
  0 &   3 & -3 & -3 \\
  0& 0  & 2 & 6
\end{pmatrix},
\]
are all different matrices representing the same solution to the
system of equations:
\[
\begin{array}{ccccccc}
       & & 3y &-& 3z &=& 2 \\
     x& +&3y&-&3z&=&-3\\
     -3x& -&9y&-&11z&=&0
\end{array}
\]
Some `forms' of these matrices are more convenient than others. One
useful form is called \dfn{row echelon form} or \dfn{triangular
  form}. An \textit{echelon} is a military term meaning a formation
(of soldiers, vehicles, and so on) that makes a ``stair step''
shape. All of the matrices below are in row echelon form:
\[
\begin{tikzpicture}
  \draw[line width=1.3em,black!15!white] (-1.9,.455) -- (1.8,.455);
  \draw[line width=1.3em,black!15!white] (-.8,.025) -- (1.8,.025);
  \draw[line width=1.3em,black!15!white] (.7,-.42) -- (1.8,-.42);
\node at (0,0) {$\begin{pmatrix}
 ~1~&2&-1&-5&0&~2~\\0&0&3&0&2&0\\0&0&0&0&1&0
  \end{pmatrix},$};
\draw (-1.9,.7) -- (-1.9,.25) -- (-.8,.25) -- (-.8, -.2) -- (.7,-.2) -- (.7,-.7);
\end{tikzpicture}
\quad\begin{tikzpicture}
  \draw[line width=13pt,black!15!white] (-.6,.455) -- (.45,.455);
  \draw[line width=13pt,black!15!white] (-.05,.025) -- (.45,.025);
\node at (0,0) {$\begin{pmatrix}
 ~4~&~0~\\0&1\\0&0
  \end{pmatrix},$};
\draw (-.6,.7) -- (-.6,.25) -- (-.05,.25) -- (-.05, -.2) -- (.45,-.2) -- (.45,-.7);
\end{tikzpicture}
\quad
\begin{tikzpicture}
  \draw[line width=1.3em,black!15!white] (-1.5,.455) -- (1.35,.455);
  \draw[line width=1.3em,black!15!white] (-1,.025) -- (1.35,.025);
  \draw[line width=1.3em,black!15!white] (-.4,-.42) -- (1.35,-.42);
\node at (0,0) {$\begin{pmatrix}
  ~1~ &   3 & -3 & ~2~  \\
  0 &   3 & -3 & ~-3~ \\
  0& 0  & 2 & 6
  \end{pmatrix}.$};
\draw (-1.5,.7) -- (-1.5,.25) -- (-1,.25) -- (-1, -.2) -- (-.4,-.2) -- (-.4,-.7);
\end{tikzpicture}
\]
We've made a stair step pattern in each matrix. Now let's make a definition.

\begin{definition}
We say a matrix $M$ is in \dfn{row echelon form} if every nonzero row
contains a nonzero entry $M_{i,j}\ne 0$ such that
\begin{itemize}
\item Every entry below $M_{i,j}$ is zero, $M_{k,\l}=0$ whenever $k> i$.
\item Every entry to the left of $M_{i,j}$ is zero, $M_{k,\l}=0$ whenever $\l < j$.
\end{itemize}
Such an $M_{i,j}$ is called a \dfn{pivot} of $M$.
\end{definition}

\begin{question}
  id in REF and id pivots
\end{question}



\subsection{How does row echelon form help?}

Let's think about our original system of equations. We've shown that
this corresponds to a matrix in row echelon from:
\[
\begin{array}{ccccccc}
       & & 3y &-& 3z &=& 2 \\
     x& +&3y&-&3z&=&-3\\
     -3x& -&9y&-&11z&=&0
\end{array}
\qquad\Longrightarrow\qquad
\begin{pmatrix}
  1 &   3 & -3 & 2  \\
  0 &   3 & -3 & -3 \\
  0& 0  & 2 & 6
\end{pmatrix}
\]
But this final matrix that we obtained from row operations, (directly)
corresponds to the following system of equations:
\[
\left(\begin{array}{ccc|c}
  1 &   3 & -3 & 2  \\
  0 &   3 & -3 & -3 \\
  0& 0  & 2 & 6
\end{array}\right)
\qquad\Longrightarrow\qquad
\begin{array}{ccccccc}
     x  &+ & 3y &-& 3z &=& 2 \\
     &  &3y&-&3z&=&-3\\
     & & & &2z&=&6
\end{array}
\]

\section{Reduced row echelon form}


Now comes the \emph{elimination} part of Gaussian elimination. 



This final example shows us the power of reducing to row echelon form, and understanding the consequences with respect to reduced row echelon form.

%Example 2.5.4 from
%https://linearalgebra.math.umanitoba.ca/math1220/section-12.html
\begin{example}
  Consider the system of linear equations:
  \begin{align*}
    x+y+z &=  1\\
    2x+y+z &=  2\\
    3x+ay+bz &= c
  \end{align*}
  Find values of $a$, $b$ and $c$ for which there are no solutions,
  one solution, or many solutions.
  \begin{solution}
    here
  \end{solution}
\end{example}
\end{document}
